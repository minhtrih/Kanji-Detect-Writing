{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Training generator with augmentation\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        rescale=1./255,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=False,\n",
    "        vertical_flip=False,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Testing generator\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "N_CLASSES = 3036\n",
    "LR = 0.001\n",
    "N_EPOCHS = 50\n",
    "N_UNITS = 128\n",
    "IMG_SIZE = 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 576840 images belonging to 3036 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "        'training_data',  # this is the target directory\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),  # all images will be resized to 150x150\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30360 images belonging to 3036 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "        'testing_data',\n",
    "        target_size=(IMG_SIZE, IMG_SIZE),\n",
    "        batch_size=BATCH_SIZE,\n",
    "        class_mode='sparse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
    "from keras.models import Sequential, Model \n",
    "\n",
    "model = MobileNet(input_shape=(IMG_SIZE, IMG_SIZE, 3), include_top=True, classes=N_CLASSES, weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 96, 96, 3)         0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, 48, 48, 32)        864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, 48, 48, 32)        288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, 48, 48, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, 48, 48, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, 48, 48, 64)        2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, 48, 48, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, 48, 48, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, 24, 24, 64)        576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, 24, 24, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, 24, 24, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, 24, 24, 128)       8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, 24, 24, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, 24, 24, 128)       16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, 24, 24, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, 24, 24, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, 12, 12, 128)       1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, 12, 12, 128)       512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, 12, 12, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, 12, 12, 256)       32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, 12, 12, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, 12, 12, 256)       65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, 12, 12, 256)       1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, 6, 6, 256)         2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, 6, 6, 256)         1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, 6, 6, 512)         131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, 6, 6, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, 6, 6, 512)         262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, 6, 6, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, 6, 6, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, 3, 3, 512)         4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, 3, 3, 512)         2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, 3, 3, 512)         0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, 3, 3, 1024)        524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, 3, 3, 1024)        9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, 3, 3, 1024)        1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, 3, 3, 1024)        4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, 3, 3, 1024)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1, 1, 1024)        0         \n",
      "_________________________________________________________________\n",
      "conv_preds (Conv2D)          (None, 1, 1, 3036)        3111900   \n",
      "_________________________________________________________________\n",
      "act_softmax (Activation)     (None, 1, 1, 3036)        0         \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 3036)              0         \n",
      "=================================================================\n",
      "Total params: 6,340,764\n",
      "Trainable params: 6,318,876\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 5.1680 - acc: 0.1007 - val_loss: 3.6318 - val_acc: 0.2318\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 3.63177, saving model to models_4/weights-improvement-01-3.63.hdf5\n",
      "Epoch 2/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.8022 - acc: 0.7814 - val_loss: 0.4588 - val_acc: 0.8706\n",
      "\n",
      "Epoch 00002: val_loss improved from 3.63177 to 0.45881, saving model to models_4/weights-improvement-02-0.46.hdf5\n",
      "Epoch 3/50\n",
      "2253/2253 [==============================] - 894s 397ms/step - loss: 0.2622 - acc: 0.9269 - val_loss: 0.2270 - val_acc: 0.9375\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.45881 to 0.22699, saving model to models_4/weights-improvement-03-0.23.hdf5\n",
      "Epoch 4/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 0.1652 - acc: 0.9541 - val_loss: 0.2404 - val_acc: 0.9329\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/50\n",
      "2253/2253 [==============================] - 892s 396ms/step - loss: 0.1237 - acc: 0.9661 - val_loss: 0.1482 - val_acc: 0.9592\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.22699 to 0.14815, saving model to models_4/weights-improvement-05-0.15.hdf5\n",
      "Epoch 6/50\n",
      "2253/2253 [==============================] - 891s 396ms/step - loss: 0.0991 - acc: 0.9728 - val_loss: 0.1910 - val_acc: 0.9484\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/50\n",
      "2253/2253 [==============================] - 894s 397ms/step - loss: 0.0838 - acc: 0.9773 - val_loss: 0.1376 - val_acc: 0.9631\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.14815 to 0.13756, saving model to models_4/weights-improvement-07-0.14.hdf5\n",
      "Epoch 8/50\n",
      "2253/2253 [==============================] - 896s 398ms/step - loss: 0.0718 - acc: 0.9804 - val_loss: 0.1932 - val_acc: 0.9478\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/50\n",
      "2253/2253 [==============================] - 886s 393ms/step - loss: 0.0647 - acc: 0.9821 - val_loss: 0.0726 - val_acc: 0.9805\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.13756 to 0.07261, saving model to models_4/weights-improvement-09-0.07.hdf5\n",
      "Epoch 10/50\n",
      "2253/2253 [==============================] - 883s 392ms/step - loss: 0.0574 - acc: 0.9843 - val_loss: 0.0883 - val_acc: 0.9774\n",
      "\n",
      "Epoch 00010: val_loss did not improve\n",
      "Epoch 11/50\n",
      "2253/2253 [==============================] - 882s 391ms/step - loss: 0.0520 - acc: 0.9859 - val_loss: 0.0653 - val_acc: 0.9834\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.07261 to 0.06526, saving model to models_4/weights-improvement-11-0.07.hdf5\n",
      "Epoch 12/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0477 - acc: 0.9872 - val_loss: 0.0777 - val_acc: 0.9803\n",
      "\n",
      "Epoch 00012: val_loss did not improve\n",
      "Epoch 13/50\n",
      "2253/2253 [==============================] - 882s 391ms/step - loss: 0.0437 - acc: 0.9882 - val_loss: 0.0684 - val_acc: 0.9829\n",
      "\n",
      "Epoch 00013: val_loss did not improve\n",
      "Epoch 14/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0405 - acc: 0.9890 - val_loss: 0.0585 - val_acc: 0.9850\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.06526 to 0.05853, saving model to models_4/weights-improvement-14-0.06.hdf5\n",
      "Epoch 15/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0378 - acc: 0.9897 - val_loss: 0.0648 - val_acc: 0.9824\n",
      "\n",
      "Epoch 00015: val_loss did not improve\n",
      "Epoch 16/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0361 - acc: 0.9902 - val_loss: 0.0555 - val_acc: 0.9866\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.05853 to 0.05551, saving model to models_4/weights-improvement-16-0.06.hdf5\n",
      "Epoch 17/50\n",
      "2253/2253 [==============================] - 880s 391ms/step - loss: 0.0333 - acc: 0.9912 - val_loss: 0.0558 - val_acc: 0.9859\n",
      "\n",
      "Epoch 00017: val_loss did not improve\n",
      "Epoch 18/50\n",
      "2253/2253 [==============================] - 883s 392ms/step - loss: 0.0321 - acc: 0.9913 - val_loss: 0.0594 - val_acc: 0.9853\n",
      "\n",
      "Epoch 00018: val_loss did not improve\n",
      "Epoch 19/50\n",
      "2253/2253 [==============================] - 882s 392ms/step - loss: 0.0303 - acc: 0.9919 - val_loss: 0.0524 - val_acc: 0.9888\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.05551 to 0.05240, saving model to models_4/weights-improvement-19-0.05.hdf5\n",
      "Epoch 20/50\n",
      "2253/2253 [==============================] - 880s 391ms/step - loss: 0.0287 - acc: 0.9923 - val_loss: 0.0463 - val_acc: 0.9892\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.05240 to 0.04634, saving model to models_4/weights-improvement-20-0.05.hdf5\n",
      "Epoch 21/50\n",
      "2253/2253 [==============================] - 880s 391ms/step - loss: 0.0269 - acc: 0.9929 - val_loss: 0.0409 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.04634 to 0.04093, saving model to models_4/weights-improvement-21-0.04.hdf5\n",
      "Epoch 22/50\n",
      "2253/2253 [==============================] - 882s 391ms/step - loss: 0.0252 - acc: 0.9932 - val_loss: 0.0472 - val_acc: 0.9890\n",
      "\n",
      "Epoch 00022: val_loss did not improve\n",
      "Epoch 23/50\n",
      "2253/2253 [==============================] - 880s 391ms/step - loss: 0.0245 - acc: 0.9935 - val_loss: 0.0534 - val_acc: 0.9879\n",
      "\n",
      "Epoch 00023: val_loss did not improve\n",
      "Epoch 24/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0239 - acc: 0.9935 - val_loss: 0.0550 - val_acc: 0.9869\n",
      "\n",
      "Epoch 00024: val_loss did not improve\n",
      "Epoch 25/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0228 - acc: 0.9939 - val_loss: 0.0400 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.04093 to 0.03998, saving model to models_4/weights-improvement-25-0.04.hdf5\n",
      "Epoch 26/50\n",
      "2253/2253 [==============================] - 880s 390ms/step - loss: 0.0217 - acc: 0.9942 - val_loss: 0.0637 - val_acc: 0.9838\n",
      "\n",
      "Epoch 00026: val_loss did not improve\n",
      "Epoch 27/50\n",
      "2253/2253 [==============================] - 879s 390ms/step - loss: 0.0218 - acc: 0.9941 - val_loss: 0.0423 - val_acc: 0.9910\n",
      "\n",
      "Epoch 00027: val_loss did not improve\n",
      "Epoch 28/50\n",
      "2253/2253 [==============================] - 881s 391ms/step - loss: 0.0210 - acc: 0.9943 - val_loss: 0.0346 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.03998 to 0.03460, saving model to models_4/weights-improvement-28-0.03.hdf5\n",
      "Epoch 29/50\n",
      "2253/2253 [==============================] - 879s 390ms/step - loss: 0.0203 - acc: 0.9945 - val_loss: 0.0366 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00029: val_loss did not improve\n",
      "Epoch 30/50\n",
      "2253/2253 [==============================] - 878s 390ms/step - loss: 0.0192 - acc: 0.9948 - val_loss: 0.0419 - val_acc: 0.9903\n",
      "\n",
      "Epoch 00030: val_loss did not improve\n",
      "Epoch 31/50\n",
      "2253/2253 [==============================] - 882s 391ms/step - loss: 0.0182 - acc: 0.9952 - val_loss: 0.0326 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.03460 to 0.03261, saving model to models_4/weights-improvement-31-0.03.hdf5\n",
      "Epoch 32/50\n",
      "2253/2253 [==============================] - 880s 391ms/step - loss: 0.0181 - acc: 0.9952 - val_loss: 0.0489 - val_acc: 0.9889\n",
      "\n",
      "Epoch 00032: val_loss did not improve\n",
      "Epoch 33/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0173 - acc: 0.9953 - val_loss: 0.0351 - val_acc: 0.9913\n",
      "\n",
      "Epoch 00033: val_loss did not improve\n",
      "Epoch 34/50\n",
      "2253/2253 [==============================] - 900s 399ms/step - loss: 0.0172 - acc: 0.9954 - val_loss: 0.0422 - val_acc: 0.9897\n",
      "\n",
      "Epoch 00034: val_loss did not improve\n",
      "Epoch 35/50\n",
      "2253/2253 [==============================] - 901s 400ms/step - loss: 0.0169 - acc: 0.9955 - val_loss: 0.0403 - val_acc: 0.9900\n",
      "\n",
      "Epoch 00035: val_loss did not improve\n",
      "Epoch 36/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0167 - acc: 0.9955 - val_loss: 0.0356 - val_acc: 0.9917\n",
      "\n",
      "Epoch 00036: val_loss did not improve\n",
      "Epoch 37/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0159 - acc: 0.9956 - val_loss: 0.0465 - val_acc: 0.9895\n",
      "\n",
      "Epoch 00037: val_loss did not improve\n",
      "Epoch 38/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0157 - acc: 0.9958 - val_loss: 0.0410 - val_acc: 0.9907\n",
      "\n",
      "Epoch 00038: val_loss did not improve\n",
      "Epoch 39/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0154 - acc: 0.9958 - val_loss: 0.0375 - val_acc: 0.9914\n",
      "\n",
      "Epoch 00039: val_loss did not improve\n",
      "Epoch 40/50\n",
      "2253/2253 [==============================] - 900s 399ms/step - loss: 0.0147 - acc: 0.9959 - val_loss: 0.0340 - val_acc: 0.9926\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00040: val_loss did not improve\n",
      "Epoch 41/50\n",
      "2253/2253 [==============================] - 899s 399ms/step - loss: 0.0145 - acc: 0.9961 - val_loss: 0.0396 - val_acc: 0.9912\n",
      "\n",
      "Epoch 00041: val_loss did not improve\n",
      "Epoch 42/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0301 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.03261 to 0.03010, saving model to models_4/weights-improvement-42-0.03.hdf5\n",
      "Epoch 43/50\n",
      "2253/2253 [==============================] - 898s 398ms/step - loss: 0.0139 - acc: 0.9961 - val_loss: 0.0332 - val_acc: 0.9925\n",
      "\n",
      "Epoch 00043: val_loss did not improve\n",
      "Epoch 44/50\n",
      "2253/2253 [==============================] - 897s 398ms/step - loss: 0.0135 - acc: 0.9964 - val_loss: 0.0324 - val_acc: 0.9926\n",
      "\n",
      "Epoch 00044: val_loss did not improve\n",
      "Epoch 45/50\n",
      "2253/2253 [==============================] - 900s 400ms/step - loss: 0.0138 - acc: 0.9963 - val_loss: 0.0334 - val_acc: 0.9922\n",
      "\n",
      "Epoch 00045: val_loss did not improve\n",
      "Epoch 46/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 0.0132 - acc: 0.9964 - val_loss: 0.0325 - val_acc: 0.9921\n",
      "\n",
      "Epoch 00046: val_loss did not improve\n",
      "Epoch 47/50\n",
      "2253/2253 [==============================] - 897s 398ms/step - loss: 0.0129 - acc: 0.9965 - val_loss: 0.0359 - val_acc: 0.9924\n",
      "\n",
      "Epoch 00047: val_loss did not improve\n",
      "Epoch 48/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 0.0129 - acc: 0.9964 - val_loss: 0.0329 - val_acc: 0.9929\n",
      "\n",
      "Epoch 00048: val_loss did not improve\n",
      "Epoch 49/50\n",
      "2253/2253 [==============================] - 898s 399ms/step - loss: 0.0127 - acc: 0.9965 - val_loss: 0.0378 - val_acc: 0.9918\n",
      "\n",
      "Epoch 00049: val_loss did not improve\n",
      "Epoch 50/50\n",
      "2253/2253 [==============================] - 877s 389ms/step - loss: 0.0123 - acc: 0.9966 - val_loss: 0.0485 - val_acc: 0.9896\n",
      "\n",
      "Epoch 00050: val_loss did not improve\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f695de98b38>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "model_file = \"models_4/weights-improvement-{epoch:02d}-{val_loss:.2f}.hdf5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(model_file, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "model.compile(loss=keras.losses.sparse_categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adadelta(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# model.load_weights('models_3/weights-improvement-85-0.06.hdf5')\n",
    "\n",
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=576840 // BATCH_SIZE,\n",
    "        epochs=50,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=30360 // BATCH_SIZE,\n",
    "        callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.load_weights('models_4/weights-improvement-42-0.03.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"model_mobilenet.json\", \"w\") as json_file:\n",
    "    json_file.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Timit ENV",
   "language": "python",
   "name": "timit_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
